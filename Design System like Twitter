1-) What this system looks like?
  
  * This system provides us to share text with other users. This is typically social networking system. When users use this system, 
  they post character sets(maximum 150 character) and they are called as "tweets". Notice that in Twitter system, if you register this
  site, you can post and read tweets, on the other hand, if you are not register (or not login) you can only read tweets. Moreover, users
  reach this system any platform like desktop application or mobile application.

2-) Requirements and goals of Twitter

  * There are typically 3 types of requirements. First one is functional requirements, second one is nonfunctional requirements and 
  third one is extended requirements. During the development process, we should determine all three requirements clearly.
  * Users can register and login.
  * Users can logout.
  * When users login, they can share or read tweets.
  * When users are not register or login, they can only read tweets.
  * Users can follow other users.
  * Users can mark some tweets as a favourite.
  * System should be highly reliable. This means that no of post should be lost.
  * System should be highly available. This means that users should reach this system whenever they want.
  * System should return the requests with minimum latency. This means that users should reach the posts nearly real lime.
  * System can be monitorized. For this purpose, we can keep the location of users, or location of shared tweets.
  * During the development of system, REST or SOAP API's can be used. (REST API is a little bit good option)
  * Additionally, when users post tweets, these tweets can contain any file or photo.
  * Notice that, if we design a system like twitter, we can determine the acceptable latency like as a 300 ms.
  * Additionally, consistency can acceptable, if the system give the request properly later.
  * Users can search the tweets during the travel the site.
  * Finally, people can answer the tweets.
  
 3-) Capacity and Estimation
 
  * If we assume that daily, 100 Million new tweets come to this system, and notice that maximum tweet size is 150 character, 
  
  * Daily storage = 100 Million * (140 * 2 + 20) = 100 Million * 300 bytes = 30 GB per day. (20 Byte for medata of tweet)
  If we think about 10 years later, 30 GB * 30 * 12 * 10 = 30 GB * 3600 = 108 TB for text tweet. Additionaly if we assume that,
  If any photo = 100 KB and any video is 2 MB and ratio is (5:1:1);
  
  100 KB * 20 Million * 30 * 12 * 10 = 200 Million * 3600 KB = 2 GB * 360 = 720 TB for photos
  2 MB * 20 Million * 30 * 12 * 10 = 400 Million * 360 MB = approximately 4*10^12 byte * 36 = 144 * 10^12 byte for videos.
  
  * This is a huge data. We need to sharding.
  
  Additionaly we can calculate bandwith estimate. Notice that for banding, we should calculate the read and write tweet capacity in a second.
  Moreover, cahcing mechanism should be used to develop this sytem. If we think that the general approximation of caching mechanism is 
  %20 for daily storage, we can easily calculate the necessity memory for caching.
  
 4-) API's
 
 * To develop this site, we can use REST API's for mobile application and desktop application. (Notice that we can also use SOAP API's)
 * There are several main API's.
  - createTweet
  - deleteTweet
  - updateTweet
  - getTweet
  - searchTweet
  - markTweet
  - followUser
  - login
  - logout
  ...etc
  
  * Notice that, key parameter should be used almost every API's because of controlling registration and monitoring system. (We can obtain
  information about users with key). A succesfull create API will return URL demonstrated by string and failed API return HTTP_Response error.
  
  5-) Think about high level system design?
  
  * First of all we notice that the system is read-heavy system and huge data will be stored for this system.
  * To provide this purpose, we should use multiple application server. (to provide minimum latency)
  * If we use multiple application server we can use load balancer for sharing incoming request.
  * We can use robin robin prenciples for sharing incoming request for load balancer, but round robin has some lack of properties.
  If server is busy or not ready to return response, load balancer will continue to send request to this server. This condition is 
  not good, so we can develop more intelligent sharing prenciples to handle this situation.
  * Also notice that we should have an database server, file stroge server and metadataserver for reducing the system load.
  * As explained later, we can use multiple cache servers and database servers for providing partitioning. Additionally,
  load balancer will be used between application servers and cache servers and application servers and file servers and application servers
  and metadata servers.
  
  6-) Database
  
  * We need to store information about users and tweets. Notice that we can use SQL or NoSQL but if we use NoSQL then we should keep
  (user, tweet)
  - Tweet (TweetID:bigInt, Content, CreationDate, Tweet Location, NumberOfFavourites) - (Except Content all of information will be kept in metadata storages)
  - Users (UserID:bigInt, Name, Email, Age, LastLogin)
  - UserFollow (UserID1, UserID2)
  - UserFavourite (UserID, TweetID, FavouriteDate)
  
  * Additionally when creating TweetID or UserID we can use Key generation service. Key generation service creates all the possible ID's and 
  store the KGS Databases before. There are two tables. First one is usedKeys secondone is nonUsedKeys. notice that, any of two servers 
  can wish to key at the same time. To handle this problem, if any key used before, database server should wish to new key from application server
  and application server should wish to new key for KGS database server. Additionally, Some keys can be kept in over the application servers.
  But if we think about when the server fails, we will lost all the keys over the application server. Notice that if we have enough key
  for this system. (8 character longs. and base64 encoding) there are approximately billions of  keys here and loosing keys are not important.
  As a brief, if server fails, server wish to new keys from the KGS database storages.
  
  7-) DataSharding
  
  * Notice that there will be huge data kept in database servers and we have a motto that system should give a request with acceptable latency.
  To providing this purpose we use partitioning. (shard datas.) There are some options for sharing. First one is hash based on userID,
  second one is hash based on tweetID, third one is hash based on tweetcreationdate etc.. If we use hash based on userID. System can be 
  unbalanced since some users may be hot or some users post tweets very little. If we use hash based on tweetID, for creating timeline
  generation, system should keep track of some process. (Like bring tweets from different servers). This causes to higher latency.
  Ä°f we use hashing with creation time, we can quicly obtain the new or hot tweets. On the other hand, obtaining latest tweets causes 
  higher latencies. Briefly, we can use hash based on tweetID and tweetCreationTime for taking advantage of both of them.
  
  8-) Caching
  
  * We can use LRU (least recently used) prenciples for caching mechanism. Additionally, we can use hottest tweets or users for caching. 
  We can use MemCache for this operation. As you know, caching operation provide us to obtain data quickly. Notice that we should determine
  the number of necessity caching servers. As we explained before, we can try to use %20 principles. 
  
  9-) Detailed explanation of high level system design
  
  * Clients applications are routed to application servers by the load balancer.
  * Application servers quicly look the caching servers by the load balancer whether data is here or not.
  * If data is not here, then application server looks to DB Shard. (We should determine the Sharding number)
  * When data is found to DB Shard, LRU caching mechanism will be used and cahce server will be updated.
  * Notice that fileStorage or metadata servers connect the application servers at the same time.
  
  10-) Data replication
  
  * To provide high reliable, we can keep data more than one servers. The best idea for replication is every always on server, two or more
  copy servers should be used. Additionally, we can use this idea that, always on servers can be used for writing data and copy servers
  can be used for only reading operations. This helps system to reduce traffic loads. Moreover, if alwayson servers (primary) fail, one of
  the secondary(copy) servers behaves like a always on server.
  
  11-) Monitoring
  
  * To measure the durability of the system, monitoring operation is more crucial.By monitoring operation we can quickly notice the 
  more needed replication, sharing, caching or load balancing.
  * We can keep new tweets in a day
  * we can measure latency.
  * we can keep location of the tweets.
  * how many tweets serving at the same time? 
  etc....
  
  
  
  
  
  
