1-) What this web site looks like?

  i-) This web site helps users to upload and store text plain or image in cloud platforms. 
  ii-) Users can easly reach this plain text or image with given unique URL
  iii-) Additionally other users can easily reach plaint text or image shared by other users by accessing URL. 
  iiii-) Additionally, users can share plain text or image with private or public options.
  
2-) System Requirements and Goals of the system

  i-) User should upload and store plain text and image then take an unique URL.
  ii-) Users should reach their uploaded plain text and image by entering this given unique URL.
  iii-) Users should choose public or private properties to determine which users can see files or which users cannot see files.
  iiii-) Other users should see the public files by accessing specific unique URL.
  iiiii-) Notice that system should be highly reliable. This means that every files should store and when server fail, files should not be lost. (Replication)
  iiiiii-) Notice that system should be highly available. This means that users should access the web site whenever they want. 
  iiiiiii-) System should return the response with minimum latency. This property is provided by using loadbalancing, partitioning, sharding, caching.
  iiiiiiii-) Additionally, system can be monitored.
  iiiiiiiii-) Rest or SOAP API's can prefer for connecting system and outer environment.
  iiiiiiiiii-) We can limit users with determine uploading maximum size file. (such as 5 MB)
  
3-) Capacity Estimation

  => Let's assume that in one day 1 Million new file comes and ratio of read write operation is 5:1
  i-) Traffic estimation
    a-) In a second => write operation 1 M / (24*3600) = 12 files/s
    b-) In a second => read operation approximately 60 files/s.
  ii-) Capacity Estimation
    a-) If we assume that average file is is 100 KB. So in one day => 100 KB * 1 M = 10 GB, in 5 years = 10 GB * 30 * 12 * 5 = 18000 GB = 18 TB in 5 years
    b-) Additionally for unique URL we can use some key service that generate unique keys. Key generation services creates the unique strings and store the data
    b-) For Key Generation Services capacity = 6 character * 8 byte * (base 64 endoding 64 ^ 6 = approximately 60 billion) = this is negligable
    c-) And we can use the approximaion of usage total capacity. We use maximum %70 capacity at the same time. So we need to 25 TB storage.
  iii-) Bandwith estimation
    a-) for write operation => 12 * 100 = 1.2 MB/s
    b-) for read operation => 60 * 100 = 6 MB/s
  iiii-) Caching estimation
    a-) For caching we can use %20 rules. This means that in a day 10 GB / 5 = 2 GB caching can be used.
    
  4-) System API's
    
    i-) We can basically prefer REST API for this web site.
    ii-) Basically three API first is uploadFile(key, url, text, private = none) return uniqueURL, second one is readFile(key, url) redirect original url, third one is deleteFile(key, url) return http response(SUCCESS or FAIL)
    
  5-) Database
    
    i-) We can prefer NoSQL databases like Dynamo or Cassandra. Because there is huge data and no relationship between URLs, this is the good option.
    ii-) We can quickly obtain the data with using NoSQL
    iii-) Basically three table should be. First one is File, User, File and User.
    
  6-) Let's first think about basically system design
    
    i-) Storage can be divided into two parts.
      a-) Metadata storage
      b-) Block storage
      c-) Client
      d-) Application server

  7-) Think about system design more deeply
    
    i-) Metadata storage
    ii-) Block storage
    iii-) Clients
    iiii-) Load balancer (client and application servers, application servers and block servers,block caches,metadata servers, metadata caches)
    iiiii-) Key generation service data storage
    iiiiii-) Block cache
    iiiiiii-) Metadata cache
    iiiiiiii-) All of services have two or more replica servers.
    
  8-) Replication and Data partitioning
  
    i-) We can use sharding (horizontal partitioning for this sytem)
    ii-) In addition, data replication can be used. (Each server has two or more copy server)
    iii-) Hash based partition should be used to provide balancing.
 
  9-) Caching
 
    i-) Notice that we use %20 rules for caching.
    ii-) In addition, block storage cache and metadata storage cache can be used.
    iii-) LRU mechanism can prefer for caching
    
 10-) Load balancer
 
    i-) We can use Round Robind principle but this principle has important problem. This cannot handle if server is busy or fail, it continue to redirect busy or fail server.
    ii-) We can create more intelligent load balancer principle for this problem.
    
